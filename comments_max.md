# Comments on the Manuscript
## metrics
- Citations: inconsitent between package and accompanying paper
    - *Why use Citations for Software, when we dont use it for papers??*
- First version
    - *very nice explanation of best practises, but what does that mean?*
    - *In addition, *
- GitHub stars
- Citations and other metrics 
    - *This especially punishes highly relied-on backends such as optimization algorithms: For example, the NLopt optimization suite is cited 1,711 times on google scholar. However, the algorithms from that suite are used in countless software packages, for example, as a backend of OpenMx which again has 811 citations. Moreover, the algorithms from that suite are all open source, and therefore serve as a reference for others. As an example, consider the lme4 package, that adapted one of the algortihms from NLopt. This package has 57,820 citations on google scholar, yet no single lme4 user probably ever cited the NLopt library.*
- Metrics for software but not for publications: 
    - *I think this is a major point and we should write more about that. For papers, the concept of rigor seems central. For software, it is not used at all, but instead the same invalid metrics are proposed that habe been condemned before.*
- Alternative: Name empirical research project 
    - *Very nice, but one could also name other software etc. that benefited, or maybe one could name university seminars using the software for teaching, etc.*

## Software Engineering standards
- Unit tests
    - *very nice, I would say this is one aspect of "rigor" for software. Other aspects worth mentioning are CI, documentation (docstrings for example) and open source; also the possibility to report bugs (and to see whether they are fixed!!), and active maintanance, and bug reporting/changelogs of the software (researchers want to know if they relied on an erroneous version of software!), reproducibility*

## lines of code
*Very nice! One could even say less lines of code are an indicator for rigor.*

## peer-review
*Very nice, this is also an aspect of rigor*

## reproducibility

## impact
*Does not exists, but I think it was already discussed unter "metrics"*

## usability
*Does not exist*

# Additional Comments

Reusability is conflated with usage. Reusability is enhanced by  best practises, usage is confalted by the size of the filed and the convenieces of Researchers. For example, closed sourde software may be used out of conveniece, but at the expense of the transperency and reproducibility of the research procedure.